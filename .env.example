# LLM API Keys (at least one required)
OPENAI_API_KEY=your_openai_api_key_here
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Python LLM Service Configuration
PYTHON_SERVICE_URL=http://127.0.0.1:5000
PYTHON_SERVICE_HOST=127.0.0.1
PYTHON_SERVICE_PORT=5000
PYTHON_SERVICE_DEBUG=false

# Encryption Key for storing credentials securely
# Generate with: node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
ENCRYPTION_KEY=your_32_byte_hex_encryption_key_here

# Proxy Configuration (optional)
PROXY_USERNAME=your_proxy_username
PROXY_PASSWORD=your_proxy_password

# Browser Configuration
HEADLESS_MODE=true
BROWSER_TIMEOUT=30000

# Automation Settings
HUMAN_DELAY_MIN=500
HUMAN_DELAY_MAX=2000
QUESTION_READING_SPEED=250
DEFAULT_THINKING_TIME=2000

# Logging
LOG_LEVEL=info
LOG_FILE=./logs/automation.log